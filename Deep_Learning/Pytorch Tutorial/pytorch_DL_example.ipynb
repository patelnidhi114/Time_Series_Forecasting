{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Play with Pytorch Basic Function"
      ],
      "metadata": {
        "id": "Nt_2V6KzLL8m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "I3fKMlkQFrXb"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(3,dtype=torch.double)\n",
        "y = torch.empty(3,dtype=torch.double)\n",
        "m = torch.rand(3,3,dtype=torch.double)"
      ],
      "metadata": {
        "id": "xWI0JvUhHSVZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y,m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPukESYnImrR",
        "outputId": "91756ba6-a8cc-434e-de88-0542386e541d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1.], dtype=torch.float64),\n",
              " tensor([5.0031e-310, 5.0031e-310, 3.9525e-322], dtype=torch.float64),\n",
              " tensor([[0.4869, 0.0831, 0.5559],\n",
              "         [0.0138, 0.6059, 0.3431],\n",
              "         [0.2372, 0.5979, 0.2361]], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = x+y\n",
        "z = torch.add(x,y)\n",
        "# z = torch.mul(x,y) #inplace y_ multiplication\n",
        "y.add_(x) # inplace y_ addition\n",
        "# y.mul_(x)\n",
        "print(z)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhCvQ92_JUXL",
        "outputId": "b2714bf9-4f22-43aa-e40c-77f1418341c6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1.], dtype=torch.float64)\n",
            "tensor([1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "riEyv_LiLH8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z,y[0]"
      ],
      "metadata": {
        "id": "Ap_XIoqjJZji",
        "outputId": "b3155f4c-2b37-4435-b7d5-9d70b2c8c806",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1.], dtype=torch.float64),\n",
              " tensor(1.2214e-313, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8TDIcTRqJadg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Neural Network in Pytorch\n",
        "\n",
        "Ref : https://www.youtube.com/watch?v=mozBidd58VQ"
      ],
      "metadata": {
        "id": "SgYcxikSLS3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "ncqK-KeiLVnf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Data"
      ],
      "metadata": {
        "id": "CnZb2P4FMRNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = datasets.MNIST(root=\"data\",download=True,train=True,transform=ToTensor())"
      ],
      "metadata": {
        "id": "VLh9MuOWMAlo",
        "outputId": "7b7ddee9-1a57-4fbc-9b12-5b4b92a84c15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 11248419.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1267905.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 9441412.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7381065.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "nU3ouZkvMNI2",
        "outputId": "e98c8208-088d-4dd0-f729-3636c5d5aca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DataLoader(train,32)"
      ],
      "metadata": {
        "id": "ZNExJGbjMVOW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "mRTotXVOOFvJ",
        "outputId": "ba031a63-a420-48a0-a097-4314cafd6c4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Refer this page for calculation : https://medium.com/@muhammadshoaibali/flattening-cnn-layers-for-neural-network-694a232eda6a"
      ],
      "metadata": {
        "id": "1sHvt4gAfjOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Conv2d(1,32,(3,3)),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32,64,(3,3)),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64,64,(3,3)),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(64*(28-6)*(28-6),10)\n",
        "\n",
        "\n",
        "      )\n",
        "    \"\"\"\n",
        "          Q : how did he got 64*(28-6)*(28-6) and he did not use max pool , is that okay?\n",
        "          This is because he didn't use padding on any of its conv layer, in general the formula is ⌊(n + 2p - k)/s⌋+1 where n=Image size, p=padding, k=Kernel_size, s=stride.   So in his case\n",
        "              image size = 28*28(n*n)\n",
        "              For Conv1\n",
        "              n = 28, p=0 which is the default value, k=3, s=1 which is also the default value,\n",
        "              ⌊(n + 2p - k)/s⌋+1 = ⌊(28 + 2(0) - 3)/1⌋+1 = 26\n",
        "              For Conv2\n",
        "              n = 26, p=0 , k=3, s=1 ,\n",
        "              ⌊(n + 2p - k)/s⌋+1 = ⌊(26 + 2(0) - 3)/1⌋+1 = 24\n",
        "              For Conv3\n",
        "              n = 24, p=0 , k=3, s=1 ,\n",
        "              ⌊(n + 2p - k)/s⌋+1 = ⌊(24 + 2(0) - 3)/1⌋+1 = 22\n",
        "              After this when you feed it to the fc layer you multiply the output channel by the size of the image which is 64*22*22\n",
        "              That is how he got 64*(28-6)*(28-6)\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "v6-OQPT0MdE4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = ImageClassifier().to('cpu')\n",
        "opt = Adam(clf.parameters(),lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ZOuNGVQQgF5H"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.forward"
      ],
      "metadata": {
        "id": "puDhP2pCrOUU",
        "outputId": "f320c5b6-8605-434a-8587-a55de49f3d16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassifier(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (5): ReLU()\n",
              "    (6): Flatten(start_dim=1, end_dim=-1)\n",
              "    (7): Linear(in_features=30976, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  for epoch in range(10):\n",
        "    for batch in dataset:\n",
        "      X,y = batch\n",
        "      yhat = clf(X)\n",
        "      loss = loss_fn(yhat,y)\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "    print(f\"EPoch:{epoch} loss is {loss.item()}\")"
      ],
      "metadata": {
        "id": "t6JL8Fc0hKR-",
        "outputId": "59328250-06df-4b55-d0e2-f0e9ba1c06d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPoch:0 loss is 0.05499428138136864\n",
            "EPoch:1 loss is 0.0026581543497741222\n",
            "EPoch:2 loss is 0.0003981966874562204\n",
            "EPoch:3 loss is 2.9311146136024036e-05\n",
            "EPoch:4 loss is 0.0003539360477589071\n",
            "EPoch:5 loss is 2.0824195416935254e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TPpJCDl6iabK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}